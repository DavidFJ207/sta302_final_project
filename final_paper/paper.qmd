---
title: "STA302 Fall 2024 Final Project Part 1: Research Proposal and Data Introduction"
author: 
- "Wendy Huang"
- "Gadiel David Flores"

date: "07/10/24"
subtitle: "Research Proposal and Data Introduction"
output: pdf_document
format: pdf
number-sections: true
bibliography: references.bib
---
# Introduction
Housing affordability and price fluctuations have become pressing issues in metropolitan areas, and Toronto is no exception.Over the past decade, housing prices have seen a steep upward trend, driven by a combination of housing supply and demand, economic, and policy-related factors.(@5causesbehindtoronto) This study aims to investigate the relationship between several key housing market indicators—namely, the number of available homes, homes sold, homes starting construction, new homes completed, and interest rate hikes—and housing prices in Toronto. By analyzing these factors, this research will contribute to a more comprehensive understanding of Toronto's housing market dynamics.

The rapid rise in housing prices has been widely debated, with supply constraints being one of the leading factors. For example, Glaeser, E. L., Gyourko, J., & Saks, R. E. (@whyhavehousingprices) employed linear regression to analyze the relationship between supply constraints and prices, showing an imbalance between supply and demand results in price hikes.

Additional studies support the notion that housing availability and construction trends influence prices. In their paper, Goodman, A. C., & Thibodeau, T. G. (@metropolitanhousing) explored the linear relationship between new housing construction and price stability in urban areas. The authors found that increased housing completions have a stabilizing effect on prices, especially in high-demand areas. 

The paper by Guiwen Bai and Yu Ma (@fundamentalhousing) uses a multi-factor regression model to study how these fundamentals, particularly the cost of borrowing and income tax impacts and interest rates, relate to housing price movements in Canada. The paper confirmed that low interest rates contribute to increased affordability, encouraging more people to enter the housing market.

Given these findings, linear regression is an appropriate tool for analyzing how these supply-side continuous variables interact to affect prices in Toronto. The clear quantitative relationship between supply predictors (available homes, homes sold, etc.) and price response aligns dynamically well with the assumptions of linear regression, making it a suitable method for this analysis. Linear regression allows us to quantify the relationship between these factors and price, providing insights into which variables have the most significant impact.

# Data Description

## Data Source

Using data from Statistics Canada, we extracted five datasets. @StatCan-NewHousingPriceIndex served as the foundation for this research paper, as it contained the main statistic we wanted to analyze. @StatCan-NewHousingPriceIndex represents the new housing price index, which calculates the average cost of new housing each month by multiplying by 100 and dividing by the base year. This provides an index reflecting housing costs for any given year and month. We then utilized @StatCan-CPI, @StatCan-GDP, @StatCan-HousingStarts, @StatCan-FinancialMarketStats, and @StatCan-HousingAbsorptions to extract our 13 predictors, including Absorption, GDP, CPI, interest rates, and Construction. Specifically, Absorption and Construction are further divided into two parts. Absorbtion is divided into semi-detached homes and single homes as well as empty and sold houses for any given month. Construction is categorized into three parts: new construction, under construction, and finished construction. These datasets were cleaned by removing missing values, converting data into whole integers, and merging them into one dataset. Additionally, the data spans from 1997 to 2016 and is divided quarterly, providing 76 entries. Lastly, we used interest rates to create our categorical predictor. This was done by comparing the entry i with entry i+1 in order to determine if there was an interest hike.   

## Response and Predictor Variables
Given our research question how do supply-side factors, such as housing availability, sales volume, construction starts, completions, and interest rate, impact housing prices in Toronto, the response variable chosen to help answer our research question is 'new housing price index'. This variable is suitable for linear regression because it is continuous, enabling us to model its relationships with multiple predictors. Additionally, since the new housing price index is influenced by economic variables, it allows us to identify trends and patterns through our linear regression model. For these reasons, it is a strong candidate for our model. Our five predictor variables are the number of available homes, homes sold, homes starting construction, new homes completed, and rate hikes

# Ethics Discussion
The datasets extracted from Statistics Canada are both trustworthy and ethically collected, as they originate from a reputable national statistical agency committed to maintaining data integrity and transparency. Statistics Canada follows strict protocols for data collection, ensuring that the information is accurate, reliable, and reflective of real market conditions (@StatCan). While the datasets themselves are typically reliable and collected following rigorous ethical standards, potential risks related to racial and ethnic disparities in housing must be acknowledged.

Ethical considerations also arise from the treatment of sensitive information, particularly regarding interest rates and housing data, which could impact individual financial circumstances. The datasets used in this study focus on aggregate data rather than individual responses, thus minimizing privacy concerns. 

Moreover, the datasets underwent thorough cleaning processes to ensure accuracy, further reinforcing their reliability for analysis. Overall, the ethical collection practices and transparency associated with these datasets support their trustworthiness for examining the impacts of supply-side factors on housing prices in Toronto.

# Preliminary Results 

Problem Definition
Focusing on the *New Housing Price Index* (NHPI) as the response variable, We will analyze economic, construction, and financial predictors such as construction activity, interest rates, and GDP. 

## **1. Data Preparation**

- **Tools Used**: Analysis was conducted in **R** using `tidyverse` for data manipulation and `car` for diagnostics.  

- **Steps Taken**:  
  - Defined **New Housing Price Index (NHPI)** as the response variable and identified predictors:  
  1. **Detached Absorption (Quarterly Average)**  
  2. **Semi Absorption (Quarterly Average)**  
  3. **Detached Unabsorbed Homes (Quarterly Average)**  
  4. **Semi Unabsorbed Homes (Quarterly Average)**  
  5. **GDP (Quarterly Average)**  
  6. **CPI (Quarterly Average)**  
  7. **Starting Detached Construction**  
  8. **Starting Semi-Detached Construction**  
  9. **Under Construction Detached Homes**  
  10. **Under Construction Semi-Detached Homes**  
  11. **Completed Construction Semi-Detached**  
  12. **Completed Construction Detached**  
  13. **Rate Hikes**
  - Removed missing values and outliers using Cook’s Distance.
  - Merged datasets from 1997–2016, ensuring quarterly granularity.  
  - **Split the Data**:  
    - Divided the dataset into training and test/validation sets.  
    - Used a common split, such as 50/50, to ensure both subsets are sufficiently large.  
    - Performed the split randomly to avoid sampling bias.  
```{r}
# Load necessary libraries
library(tidyverse)
library(here)
library(caret)

# Load the dataset
data <- read_csv(here::here("data/analysis_data/analysis_data.csv"))

# response variable and predictors
response <- "Quarterly_Average"
predictors <- c(
  "Detached_Absorption_Quarterly_Avg",
  "Semi_Absorption_Quarterly_Avg",
  "Detached_Unabsorbed_Quarterly_Avg",
  "Semi_Unabsorbed_Quarterly_Avg",
  "GDP_Quarterly_Avg",
  "CPI_Quarterly_Avg",
  "Starting_Detached_Construction",
  "Starting_Semi_Construction",
  "Under_Construction_Detached",
  "Under_Construction_Semi",
  "Completed_Construction_Semi",
  "Completed_Construction_Detached",
  "rates"
)

# Subset the relevant data
selected_data <- data %>%
  dplyr::select(c(response, all_of(predictors)))

# Clean Data

## Handle missing values
cleaned_data <- selected_data %>%
  drop_na()

## Remove duplicates
cleaned_data <- cleaned_data %>%
  distinct()


# Fit an initial regression model
model <- lm(as.formula(paste(response, "~", paste(predictors, collapse = " + "))), data = cleaned_data)

# Calculate Cook's Distance
cooks_d <- cooks.distance(model)

# Identify influential points
influential_points <- which(cooks_d > 4 / (nrow(cleaned_data) - length(model$coefficients)))

# Exclude influential observations
cleaned_data <- cleaned_data[-influential_points, ]

# Split the Data
set.seed(123) # Ensure reproducibility
train_index <- createDataPartition(cleaned_data[[response]], p = 0.5, list = FALSE)
train_data <- cleaned_data[train_index, ]
test_data <- cleaned_data[-train_index, ]

list(
  training_set = train_data,
  test_set = test_data
)


```

## **2. Exploratory Data Analysis (EDA)**
- **Tools Used**: `ggplot2` for visualization and `corrplot` for examining correlations.  
- **Key Insights**:  
  - **Scatterplots** indicated potential linear relationships between predictors and NHPI.  
  - **Variance Inflation Factors (VIFs)** flagged multicollinearity among construction-related predictors, necessitating feature selection or transformation.  
  - Outliers were identified, influencing NHPI trends, and removed to enhance model accuracy.  
  - **Explore Training and Test Sets**:  
    - Performed EDA on both `training_set` and `test_set` to ensure consistency and reliability.  
    - Compared distributions, means, variances, and shapes of variables across both sets to ensure similarity.  
    - Checked for any skews, extreme observations, or discrepancies between the training and test sets that could impact model generalizability.
    
### Train Data
```{r}
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(car)       # For assumption checks like residual plots
library(corrplot)  # For correlation matrix visualization
library(broom)     # For augmenting model output
library(dplyr)

# Define predictors and response variable
response <- "Quarterly_Average"
predictors <- setdiff(names(train_data), c("Quarter", response))

# Subset relevant data from the training set
eda_training_data <- train_data %>%
  select(all_of(c(response, predictors)))

### **1. Visualize Relationships in Training Set** ###
# Scatterplots for predictors in the training set
for (predictor in predictors) {
  p <- ggplot(eda_training_data, aes_string(x = predictor, y = response)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    labs(title = paste("Scatterplot of", response, "vs", predictor, "(Training Set)"),
         x = predictor, y = response) +
    theme_minimal()
  
  print(p)  # Explicitly print the plot
}

### **2. Correlation Analysis in Training Set** ###
# Correlation matrix for the training set
cor_matrix_training <- cor(eda_training_data, use = "complete.obs")
print(cor_matrix_training)
corrplot(cor_matrix_training, method = "circle", type = "upper", tl.col = "black", tl.srt = 45)

### **3. Fit Linear Regression Model on Training Set** ###
# Fit the model using the training set
model_training <- lm(as.formula(paste(response, "~", paste(predictors, collapse = " + "))), data = eda_training_data)
summary(model_training)

# Extract residuals and fitted values from the training model
residuals_training <- resid(model_training)
fitted_values_training <- fitted(model_training)

# Calculate Variance Inflation Factors (VIF) for the training model
vif_training <- vif(model_training)
print(vif_training)

### **4. Outlier Detection in Training Set** ###
# Identify influential points using Cook's Distance
cooks_d_training <- cooks.distance(model_training)
influential_points_training <- which(cooks_d_training > 4 / (nrow(eda_training_data) - length(model_training$coefficients)))

# Output details of influential points
if (length(influential_points_training) > 0) {
  print(paste("Number of influential points:", length(influential_points_training)))
  print("Influential points identified:")
  print(influential_points_training)
} else {
  print("No influential points detected.")
}

```
### Test Data
```{r}
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(car)       # For assumption checks like residual plots
library(corrplot)  # For correlation matrix visualization
library(broom)     # For augmenting model output
library(dplyr)

# Define predictors and response variable
response <- "Quarterly_Average"
predictors <- setdiff(names(test_data), c("Quarter", response))

# Subset relevant data from the test set
eda_test_data <- test_data %>%
  select(all_of(c(response, predictors)))

### Visualize Relationship
# Scatterplots for predictors in the test set
for (predictor in predictors) {
  p <- ggplot(eda_test_data, aes_string(x = predictor, y = response)) +
    geom_point(alpha = 0.7) +
    geom_smooth(method = "lm", color = "blue", se = FALSE) +
    labs(title = paste("Scatterplot of", response, "vs", predictor, "(Test Set)"),
         x = predictor, y = response) +
    theme_minimal()
  
  print(p)  # Explicitly print the plot
}

### Correlation Analysis
# Correlation matrix for the test set
cor_matrix_test <- cor(eda_test_data, use = "complete.obs")
print(cor_matrix_test)
corrplot(cor_matrix_test, method = "circle", type = "upper", tl.col = "black", tl.srt = 45)

### Linear Regression Model
# Fit the model using the test set
model_test <- lm(as.formula(paste(response, "~", paste(predictors, collapse = " + "))), data = eda_test_data)
summary(model_test)

# Extract residuals and fitted values from the test model
residuals_test <- resid(model_test)
fitted_values_test <- fitted(model_test)

# Calculate Variance Inflation Factors (VIF) for the test model
vif_test <- vif(model_test)
print(vif_test)

### Outlier Test Set
# Identify influential points using Cook's Distance
cooks_d_test <- cooks.distance(model_test)
influential_points_test <- which(cooks_d_test > 4 / (nrow(eda_test_data) - length(model_test$coefficients)))

# Output details of influential points
if (length(influential_points_test) > 0) {
  print(paste("Number of influential points:", length(influential_points_test)))
  print("Influential points identified:")
  print(influential_points_test)
} else {
  print("No influential points detected.")
}

```
Our analysis revealed that housing prices are influenced by various factors, such as absorption rates, unabsorbed homes, and economic indicators like GDP and CPI. Some predictors, like unabsorbed homes and GDP, have a strong and significant effect, while others, like construction starts, show weaker or inconsistent relationships. However, the strong connection between certain predictors, like GDP and CPI, makes it harder to separate their individual impacts, which complicates the analysis. By addressing these overlaps and focusing on the most reliable factors, we can build a clearer and more accurate model for understanding housing price trends.

## **3. Model Building**
- **Tools Used**: `lm` in R for linear regression modeling.  
- **Steps Taken**:  
  - Conducted all model building, assessments, and diagnostics on the **train_data** to ensure the model generalizes well to unseen data.  
  - Included key predictors based on theoretical relevance and statistical significance.  
  - Applied transformations to predictors to improve linearity and stabilize variance.  
  - Addressed residual skewness with a Box-Cox transformation of the response variable.  
  - Selected the final model based on diagnostics from the training set, ensuring adherence to regression assumptions and a good fit.  
  
```{r}
# Load necessary libraries
library(car)      # For VIF calculation
library(MASS)     # For Box-Cox transformation
library(lmtest)   # For diagnostic tests

# Transform predictors
train_data$Detached_Absorption_Quarterly_Avg <- log(train_data$Detached_Absorption_Quarterly_Avg + 1)
train_data$Starting_Detached_Construction <- log(train_data$Starting_Detached_Construction + 1)
train_data$Under_Construction_Detached <- log(train_data$Under_Construction_Detached + 1)
train_data$Completed_Construction_Semi <- log(train_data$Completed_Construction_Semi + 1)
train_data$Detached_Unabsorbed_Quarterly_Avg <- log(train_data$Detached_Unabsorbed_Quarterly_Avg + 1)


# Box-Cox transformation
bc <- boxcox(Quarterly_Average ~ Detached_Absorption_Quarterly_Avg +
                                Starting_Detached_Construction +
                                Detached_Unabsorbed_Quarterly_Avg +
                                Under_Construction_Detached +
                                Completed_Construction_Semi +
                                CPI_Quarterly_Avg,
             data = train_data, plotit = FALSE)
lambda <- bc$x[which.max(bc$y)]

if (lambda == 0) {
  train_data$Quarterly_Average <- log(train_data$Quarterly_Average)
} else {
  train_data$Quarterly_Average <- (train_data$Quarterly_Average^lambda - 1) / lambda
}

# Fit the linear regression model
model <- lm(Quarterly_Average ~ Detached_Absorption_Quarterly_Avg +
                                   Starting_Detached_Construction +
                                   Detached_Unabsorbed_Quarterly_Avg +
                                   Under_Construction_Detached +
                                   Completed_Construction_Semi +
                                   CPI_Quarterly_Avg,
            data = train_data)

# multicollinearity
vif_values <- vif(model)
print("VIF Values:")
print(vif_values)


# final model
print("Final Model Summary:")
summary(model)

```
  
### Summary of Results:

The multiple linear regression model for predicting the Box-Cox transformed quarterly average housing prices (\(bc\_Quarterly\_Average\)) shows a strong overall fit (\(R^2 = 0.9839\), \(Adj. R^2 = 0.9806\), \(F\)-statistic \(p < 2.2e-16\)), indicating that the selected predictors explain nearly all variability in the response variable. Key significant predictors include **Detached_Unabsorbed_Quarterly_Avg** (\(p = 8.58e-05\), positive effect), **Under_Construction_Detached** (\(p = 9.90e-06\), positive effect), and **CPI_Quarterly_Avg** (\(p = 2.34e-11\), strong positive effect). **Detached_Absorption_Quarterly_Avg** (\(p = 0.0293\)) exhibits a significant negative relationship with prices. While **Starting_Detached_Construction** (\(p = 0.0831\)) and **Completed_Construction_Semi** (\(p = 0.1387\)) are less significant, their inclusion is supported by theoretical relevance.

### Justification for Transformations:

Transformations were applied to stabilize variance, improve linearity, and address multicollinearity. Log-transformations were used for predictors like **Detached_Absorption_Quarterly_Avg**, **Starting_Detached_Construction**, and **Under_Construction_Detached** to handle skewness and make relationships with the response variable more linear. Standardizing **CPI_Quarterly_Avg** addressed extreme multicollinearity, as it was highly correlated with other predictors. A Box-Cox transformation was applied to the response variable to correct residual skewness and ensure homoscedasticity. These steps collectively improved model diagnostics, reduced variance inflation factors (VIFs), and ensured compliance with regression assumptions, resulting in a more robust and interpretable model.

## **4. Assessment of Assumptions**
- **Tools Used**: Residual diagnostics using residual vs. fitted plots, Q-Q plots, and histograms.  
- **Findings**:  
  - **Linearity**: Residual plots indicated clustering around fitted values, with minor deviations suggesting potential non-linearity.  
  - **Homoscedasticity**: Fanning in residuals for predictors
  - **Normality**: Q-Q plots looks for alignment with normality
  - **Influential Points**
  
```{r}
# Load necessary libraries
library(ggplot2)
library(car)
library(MASS)
library(lmtest)

# Calculate residuals and fitted values
residuals <- resid(model)
fitted_values <- fitted(model)

# Residuals vs Fitted Values Plot 
ggplot(data = NULL, aes(x = fitted_values, y = residuals)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values",
       y = "Residuals") +
  theme_minimal()

# Residuals vs Each Predictor
predictors <- c("Detached_Absorption_Quarterly_Avg", 
                "Starting_Detached_Construction", 
                "Detached_Unabsorbed_Quarterly_Avg", 
                "Under_Construction_Detached", 
                "Completed_Construction_Semi", 
                "CPI_Quarterly_Avg")

for (predictor in predictors) {
  p <- ggplot(data = train_data, aes_string(x = predictor, y = "residuals")) +
    geom_point(alpha = 0.7) +
    geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
    labs(title = paste("Residuals vs", predictor),
         x = predictor,
         y = "Residuals") +
    theme_minimal()
  
  print(p) 
  }

# Normal Q-Q Plot
qqnorm(residuals, main = "Normal Q-Q Plot")
qqline(residuals, col = "red")

par(mfrow = c(2, 2)) 
plot(model)            
par(mfrow = c(1, 1))  

# Cook's Distance for Influential Points
cooksd <- cooks.distance(model)
plot(cooksd, type = "h", main = "Cook's Distance",
     xlab = "Observation", ylab = "Cook's Distance")
abline(h = 4/(nrow(train_data) - length(coef(model))), col = "red", lty = 2)

# VIF for Multicollinearity
vif_values <- vif(model)
print("Variance Inflation Factor (VIF) Values:")
print(vif_values)

```

The diagnostic analysis of the model shows that it performs well overall, but there are a few areas for improvement. Most predictors have acceptable relationships with the outcome variable, and the errors (residuals) are mostly normal, as shown in the Q-Q plot. However, some variables, like **CPI_Quarterly_Avg** and **log_Under_Construction_Detached**, show signs of overlap or dependency (multicollinearity), which could affect the stability of the results. A slight unevenness in the spread of errors (heteroscedasticity) suggests that adjustments, such as transformations, might improve the model's accuracy. One observation (Observation 10) has a bit more influence on the model than others, but it's not severe. Overall, the model is strong and reliable, but fine-tuning and closer inspection of specific predictors could make it even better.

## **5. Model Diagnostics**
- **Tools Used**: Performance metrics such as \( R^2 \), Adjusted \( R^2 \), AIC, BIC, and RMSE.  
- **Model Fit**:  
  - **\( R^2 \)**:
  - **Adjusted \( R^2 \)**
  - **AIC/BIC**:  
```{r}
# Load necessary libraries
library(Metrics)  # For RMSE calculation

# Model Performance Metrics
model_summary <- summary(model)

# Extract R^2 and Adjusted R^2
r_squared <- model_summary$r.squared
adj_r_squared <- model_summary$adj.r.squared

# AIC and BIC
aic <- AIC(model)
bic <- BIC(model)

# RMSE
residuals <- residuals(model)
rmse <- sqrt(mean(residuals^2))

# Results
cat("Model Performance Metrics:\n")
cat("R-squared: ", round(r_squared, 4), "\n")
cat("Adjusted R-squared: ", round(adj_r_squared, 4), "\n")
cat("AIC: ", round(aic, 4), "\n")
cat("BIC: ", round(bic, 4), "\n")
cat("RMSE: ", round(rmse, 4), "\n")

```

## **6. Model Validation**

```{r}

# Step 1: Use the model to predict on test_data
predictions <- predict(model, newdata = test_data)

# Step 2: Calculate residuals
residuals <- test_data$Quarterly_Average - predictions
# Replace `Quarterly_Average` with the actual response variable name in test_data

# Step 3: Compute Mean Squared Error (MSE) for test_data
mse_test <- mean(residuals^2)
cat("Mean Squared Error (MSE) on Test Data:", mse_test, "\n")

# Step 4: Compute R-squared for test_data
ss_total <- sum((test_data$Quarterly_Average - mean(test_data$Quarterly_Average))^2)
ss_residual <- sum(residuals^2)
r_squared_test <- 1 - (ss_residual / ss_total)
cat("R-squared on Test Data:", r_squared_test, "\n")

# Step 7: Print validation results
cat("Validation Results:\n")
cat("Mean Squared Error (Test Data):", mse_test, "\n")
cat("R-squared (Test Data):", r_squared_test, "\n")

```
 

## **7. Conclusion of Methods**

\newpage  

# Bibliography  